{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d3595a7",
   "metadata": {},
   "source": [
    "# Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "061a1576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import make_scorer, fbeta_score, accuracy_score\n",
    "\n",
    "\n",
    "from scripts.nested_CV import nested_cv, nested_cv_multi\n",
    "from scripts.skwrapped_kernels import dtw_SVC, rbf_SVC, poly_SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96f7865f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 60) (200,)\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "file_path = \"../data/laser.mat\"\n",
    "mat = loadmat(file_path)\n",
    "\n",
    "X = mat[\"X\"]\n",
    "y = mat[\"Y\"].reshape(200)\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ccaaa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs\n",
    "seed = 571489  # for repeatability\n",
    "np.random.seed(42)\n",
    "\n",
    "fbeta_scorer = make_scorer(fbeta_score, beta=2, pos_label=-1)\n",
    "accuracy_scorer = make_scorer(accuracy_score)\n",
    "\n",
    "score_dict = {\"f2\": fbeta_scorer, \"accuracy\": accuracy_scorer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4db8dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the data\n",
    "X = (X - X.mean(axis=1, keepdims=True)) / X.std(axis=1, keepdims=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2305244b",
   "metadata": {},
   "source": [
    "# Support Vector Machines\n",
    "\n",
    "Classifiers, that use the hinge loss and use the L2 regularizer\n",
    "\n",
    "In the dual mode, they can be used in conjunction with kernel methods, which is what is employed in the following notebook.\n",
    "\n",
    "The optimization criterion of the dual SVM is given by:\n",
    "$$\n",
    "\\underset{\\beta}{max} \\space \\sum_{i=1}^{n} \\space \\beta_{i} - \\frac{1}{2} \\space \\sum_{i,j=1}^{n} \\space \\beta_{i}\\beta_{j}y_{i}y_{j}k(x_{i},x_{j}), \n",
    "\\newline \n",
    "\\text{such that} \\space 0 \\le \\beta_{i} \\le \\lambda\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc60d4d3",
   "metadata": {},
   "source": [
    "## 1. SVC with Polynomial Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0642267d",
   "metadata": {},
   "source": [
    "### Description\n",
    "The idea here is to map the data into a higher dimensional space, such that data is linearly seperable in that space and we can then perform linear classification\n",
    "\n",
    "The polynomial kernel is:\n",
    "$$ k_{\\text{poly}}(x, x') = (x^{\\text{T}}x' + c)^{p} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abd6a36",
   "metadata": {},
   "source": [
    "### Nested CV\n",
    "We run a nested cross validation function for the following hyperparameters of the Polynomial Kernel:\n",
    "- p - degree of polynomial\n",
    "- lambda (C) - regularization coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8ba11c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>RESULTS<<<<\n",
      "Mean scores over 5 by 5 rounds of Nested CV  {'f2': 0.9740150485636798, 'accuracy': 0.9649999999999999}\n",
      "Best parameters  {'C': 0.001, 'degree': 4}\n"
     ]
    }
   ],
   "source": [
    "param_grid_poly = {\"C\": [0.001, 0.01, 0.1, 1, 10, 100], \"degree\": [2, 3, 4, 5, 6]}\n",
    "\n",
    "results_poly = nested_cv_multi(\n",
    "    poly_SVC(), X, y, param_grid_poly, scoring=score_dict, random_state=seed\n",
    ")\n",
    "print(\">>>>RESULTS<<<<\")\n",
    "print(\"Mean scores over 5 by 5 rounds of Nested CV \", results_poly[\"mean_scores\"])\n",
    "print(\"Best parameters \", results_poly[\"star_params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53e0c524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'outer_scores': [{'f2': 0.9803921568627451, 'accuracy': 0.95}, {'f2': 0.9595959595959596, 'accuracy': 0.975}, {'f2': 0.9595959595959596, 'accuracy': 0.975}, {'f2': 0.9803921568627451, 'accuracy': 0.95}, {'f2': 0.9900990099009901, 'accuracy': 0.975}], 'mean_scores': {'f2': 0.9740150485636798, 'accuracy': 0.9649999999999999}, 'std_scores': {'f2': 0.012295113550790568, 'accuracy': 0.012247448713915901}, 'best_params': [{'C': 0.001, 'degree': 5}, {'C': 0.001, 'degree': 6}, {'C': 0.001, 'degree': 5}, {'C': 0.001, 'degree': 4}, {'C': 0.001, 'degree': 4}], 'star_params': {'C': 0.001, 'degree': 4}}\n"
     ]
    }
   ],
   "source": [
    "print(results_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce7f4c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1] [1]\n"
     ]
    }
   ],
   "source": [
    "clf_poly = poly_SVC(C=0.001, degree=4)\n",
    "clf_poly.fit(np.delete(X, [35, 162], axis=0), np.delete(y, [35, 162], axis=0))\n",
    "\n",
    "odd_laser_faulty = clf_poly.predict([X[35]])\n",
    "odd_laser_non_faulty = clf_poly.predict([X[162]])\n",
    "print(odd_laser_faulty, odd_laser_non_faulty)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524d259c",
   "metadata": {},
   "source": [
    "## 2. SVC with RBF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37f85ba",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "The idea here is to use the squard euclidean distance between vectors as a similarity measure. This creates, gaussian \"hills\" around samples in the original feature space. Furthermore, since we have a dimension for every data point, this kernel maps to an infinite dimensional space.\n",
    "\n",
    "The RBF Kernel is:\n",
    "$$ k_{\\text{RBF}}(x,x') = exp(-\\gamma ||x-x'||^{2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b664c74b",
   "metadata": {},
   "source": [
    "### Nested CV\n",
    "We run a nested cross validation function for the following hyperparameters of the RBF Kernel:\n",
    "- gamma - scaling of the RBF function\n",
    "- lambda - regularization coefficient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d48f80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>RESULTS<<<<\n",
      "Mean scores over 5 by 5 rounds of Nested CV  {'f2': 0.9540069130692537, 'accuracy': 0.93}\n",
      "Best parameters  {'C': 1, 'gamma': 0.1}\n"
     ]
    }
   ],
   "source": [
    "param_grid_rbf = {\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    \"gamma\": [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "}\n",
    "results_rbf = nested_cv_multi(\n",
    "    rbf_SVC(), X, y, param_grid=param_grid_rbf, scoring=score_dict, random_state=seed\n",
    ")\n",
    "\n",
    "print(\">>>>RESULTS<<<<\")\n",
    "print(\"Mean scores over 5 by 5 rounds of Nested CV \", results_rbf[\"mean_scores\"])\n",
    "print(\"Best parameters \", results_rbf[\"star_params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e04602fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'outer_scores': [{'f2': 0.9523809523809523, 'accuracy': 0.875}, {'f2': 0.9900990099009901, 'accuracy': 0.975}, {'f2': 0.8762886597938144, 'accuracy': 0.925}, {'f2': 0.9803921568627451, 'accuracy': 0.95}, {'f2': 0.970873786407767, 'accuracy': 0.925}], 'mean_scores': {'f2': 0.9540069130692537, 'accuracy': 0.93}, 'std_scores': {'f2': 0.04080706458523105, 'accuracy': 0.033166247903553984}, 'best_params': [{'C': 10, 'gamma': 0.1}, {'C': 1, 'gamma': 0.1}, {'C': 0.001, 'gamma': 10}, {'C': 1, 'gamma': 0.01}, {'C': 10, 'gamma': 0.1}], 'star_params': {'C': 1, 'gamma': 0.1}}\n"
     ]
    }
   ],
   "source": [
    "print(results_rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0427f052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1] [-1]\n"
     ]
    }
   ],
   "source": [
    "clf_rbf = rbf_SVC(C=1, gamma=0.1)\n",
    "clf_rbf.fit(np.delete(X, [35, 162], axis=0), np.delete(y, [35, 162], axis=0))\n",
    "\n",
    "odd_laser_faulty = clf_rbf.predict([X[35]])\n",
    "odd_laser_non_faulty = clf_rbf.predict([X[162]])\n",
    "print(odd_laser_faulty, odd_laser_non_faulty)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cd6b0d",
   "metadata": {},
   "source": [
    "## 3. SVC with DTW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b363e112",
   "metadata": {},
   "source": [
    "## Description\n",
    "The idea here is to find the similarity of time series, that may not be aligned/ are out of phase or are moving at different rates and/or are of different lengths. The kernel is in the form of an RBF kernel, but uses the DTW distance of the time series.\n",
    "\n",
    "Given a metric $d: X \\times X \\rightarrow \\mathbb{R}_{\\geq 0}$ on the input space $X$, the family of *DTW Kernels* is given as:\n",
    "\n",
    "$$ k_{\\text{DTW}}(x, x') = e^{- \\lambda d_{\\text{DTW}}(x, x'; d)}, $$\n",
    "\n",
    "for sequences $x, x' \\in X^+ := \\bigcup_{n \\geq 1}{X^n}$ of lengths $|x|$ and $|x'|$. The *DTW distance metric* $d_{\\text{DTW}}$ is then given by $\\gamma(|x|, |x'|)$, where the helper function $\\gamma$ is defined recursively via:\n",
    "\n",
    "$$ \\gamma(i, j) = \\begin{cases} d(x_i, x_j') + \\min\\left(\\gamma(i-1, j-1), \\gamma(i-1, j), \\gamma(i, j-1)\\right) & (1 \\leq i \\leq |x|, \\, 1 \\leq j \\leq |x'|), \\\\ \n",
    "\\infty & i = 0 \\vee j = 0, \\\\\n",
    "0 & (i, j) = (0, 0). \\end{cases}\n",
    "$$\n",
    "Source: Lab jupyter notebooks\n",
    "\n",
    "A more visual explanation (source: [Herman Kamper](https://www.youtube.com/watch?v=9GdbMc4CEhE)): <br>\n",
    "![image](../diagrams/DTW.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a71793",
   "metadata": {},
   "source": [
    "### Nested CV\n",
    "We run a nested cross validation function for the following hyperparameters of the DTW Kernel:\n",
    "- gamma - smoothing of the DTW function\n",
    "- d - distance\n",
    "- lambda - regularization coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e991228a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>RESULTS<<<<\n",
      "Mean scores over 5 by 5 rounds of Nested CV  {'f2': 0.998019801980198, 'accuracy': 0.9949999999999999}\n",
      "Best parameters  {'C': 1, 'gamma': 0.1, 'inner_dist': 'euclidean'}\n"
     ]
    }
   ],
   "source": [
    "param_grid_dtw = {\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    \"gamma\": [0.001, 0.01, 0.1, 1],\n",
    "    \"inner_dist\": [\"euclidean\", \"squared euclidean\"],\n",
    "}\n",
    "\n",
    "results_dtw = nested_cv_multi(\n",
    "    dtw_SVC(), X, y, param_grid_dtw, scoring=score_dict, random_state=seed\n",
    ")\n",
    "\n",
    "print(\">>>>RESULTS<<<<\")\n",
    "print(\"Mean scores over 5 by 5 rounds of Nested CV \", results_dtw[\"mean_scores\"])\n",
    "print(\"Best parameters \", results_dtw[\"star_params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69d8c141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'outer_scores': [{'f2': 0.9900990099009901, 'accuracy': 0.975}, {'f2': 1.0, 'accuracy': 1.0}, {'f2': 1.0, 'accuracy': 1.0}, {'f2': 1.0, 'accuracy': 1.0}, {'f2': 1.0, 'accuracy': 1.0}], 'mean_scores': {'f2': 0.998019801980198, 'accuracy': 0.9949999999999999}, 'std_scores': {'f2': 0.003960396039603964, 'accuracy': 0.010000000000000009}, 'best_params': [{'C': 1, 'gamma': 0.1, 'inner_dist': 'euclidean'}, {'C': 1, 'gamma': 0.1, 'inner_dist': 'euclidean'}, {'C': 1, 'gamma': 0.1, 'inner_dist': 'euclidean'}, {'C': 1, 'gamma': 0.1, 'inner_dist': 'euclidean'}, {'C': 1, 'gamma': 0.1, 'inner_dist': 'euclidean'}], 'star_params': {'C': 1, 'gamma': 0.1, 'inner_dist': 'euclidean'}}\n"
     ]
    }
   ],
   "source": [
    "print(results_dtw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cc54770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1] [-1]\n"
     ]
    }
   ],
   "source": [
    "clf_dtw = dtw_SVC(C=1, gamma=0.1)\n",
    "clf_dtw.fit(np.delete(X, [35, 162], axis=0), np.delete(y, [35, 162], axis=0))\n",
    "\n",
    "odd_laser_faulty = clf_dtw.predict([X[35]])\n",
    "odd_laser_non_faulty = clf_dtw.predict([X[162]])\n",
    "print(odd_laser_faulty, odd_laser_non_faulty)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
